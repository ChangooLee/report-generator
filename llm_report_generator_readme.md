# LLM ê¸°ë°˜ ëŒ€í™”í˜• ë¦¬í¬íŠ¸ ìƒì„± ì„œë¹„ìŠ¤

Qwen2.5-Coderë¥¼ í™œìš©í•˜ì—¬ ìì—°ì–´ ëŒ€í™”ì—ì„œ ì¸í„°ë™í‹°ë¸Œ HTML/JS ì›¹ ë¦¬í¬íŠ¸ë¥¼ ìë™ ìƒì„±í•˜ëŠ” ì™„ì „ ì˜¤í”„ë¼ì¸ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ìš”ì²­í•˜ë©´, AIê°€ í•´ë‹¹ ìš”ì²­ì„ ì´í•´í•˜ê³  JSON ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì°¨íŠ¸ì™€ ì‹œê°í™”ê°€ í¬í•¨ëœ ì™„ì „í•œ HTML ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ëª¨ë“  ì²˜ë¦¬ëŠ” ì„œë²„ ë‚´ë¶€ì—ì„œ ì´ë£¨ì–´ì§€ë©°, ê²°ê³¼ëŠ” Nginxë¥¼ í†µí•´ ì›¹ URLë¡œ ì œê³µë©ë‹ˆë‹¤.

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ì‚¬ìš©ì ëŒ€í™”   â”‚â”€â”€â”€â–¶â”‚  ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°   â”‚â”€â”€â”€â–¶â”‚ Qwen2.5-Coder  â”‚
â”‚   (ìì—°ì–´)      â”‚    â”‚   (FastAPI)      â”‚    â”‚   (vLLM)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Nginx ì„œë²„    â”‚â—€â”€â”€â”€â”‚   íŒŒì¼ ì‹œìŠ¤í…œ    â”‚â—€â”€â”€â”€â”‚  ì½”ë“œ ì‹¤í–‰í™˜ê²½   â”‚
â”‚  (ë¦¬í¬íŠ¸ í˜¸ìŠ¤íŒ…) â”‚    â”‚ (/reports/*.html)â”‚    â”‚   (Docker)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   MCP ë°ì´í„°     â”‚
                       â”‚ (JSON ë²ˆë“¤ë“¤)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
report-generator/
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”œâ”€â”€ orchestrator.py         # ì „ì²´ ë¡œì§ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”‚   â”œâ”€â”€ llm_client.py          # Qwen2.5-Coder í´ë¼ì´ì–¸íŠ¸
â”‚   â”œâ”€â”€ code_executor.py       # ì½”ë“œ ì‹¤í–‰ í™˜ê²½ ê´€ë¦¬
â”‚   â”œâ”€â”€ data_manager.py        # MCP ë°ì´í„° ê´€ë¦¬
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ file_utils.py
â”‚       â”œâ”€â”€ security.py
â”‚       â””â”€â”€ templates.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mcp_bundles/           # MCP JSON ë°ì´í„° ë²ˆë“¤ë“¤
â”‚   â”‚   â”œâ”€â”€ sales_data.json
â”‚   â”‚   â”œâ”€â”€ user_analytics.json
â”‚   â”‚   â””â”€â”€ financial_reports.json
â”‚   â””â”€â”€ schemas/               # ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base_report.html       # ë¦¬í¬íŠ¸ ê¸°ë³¸ í…œí”Œë¦¿
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ system_prompt.txt
â”‚       â””â”€â”€ code_generation_prompt.txt
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”œâ”€â”€ chart.min.js       # Chart.js ë¼ì´ë¸ŒëŸ¬ë¦¬
â”‚   â”‚   â”œâ”€â”€ d3.min.js          # D3.js ë¼ì´ë¸ŒëŸ¬ë¦¬
â”‚   â”‚   â””â”€â”€ plotly.min.js      # Plotly.js ë¼ì´ë¸ŒëŸ¬ë¦¬
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ report.css         # ë¦¬í¬íŠ¸ ìŠ¤íƒ€ì¼
â”‚   â””â”€â”€ fonts/                 # ì˜¤í”„ë¼ì¸ í°íŠ¸
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ app.Dockerfile         # ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”œâ”€â”€ executor.Dockerfile    # ì½”ë“œ ì‹¤í–‰ í™˜ê²½
â”‚   â””â”€â”€ nginx.Dockerfile       # Nginx ì›¹ì„œë²„
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ nginx.conf
â”‚   â”œâ”€â”€ uvicorn.conf
â”‚   â””â”€â”€ logging.conf
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh              # ì´ˆê¸° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ start_services.sh     # ì„œë¹„ìŠ¤ ì‹œì‘
â”‚   â””â”€â”€ download_model.py     # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
â””â”€â”€ reports/                  # ìƒì„±ëœ ë¦¬í¬íŠ¸ ì €ì¥ì†Œ
```

## ğŸš€ ì„¤ì¹˜ ë° ì„¤ì •

### 1. í™˜ê²½ ì¤€ë¹„

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd report-generator

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ ì„¤ì •ê°’ ì…ë ¥

# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x scripts/*.sh
```

### 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (.env)

```bash
# ì„œë¹„ìŠ¤ ì„¤ì •
API_HOST=0.0.0.0
API_PORT=8000
NGINX_PORT=80

# vLLM ì„¤ì •
VLLM_HOST=0.0.0.0
VLLM_PORT=8001
MODEL_NAME=Qwen/Qwen2.5-Coder-32B-Instruct
GPU_MEMORY_UTILIZATION=0.8

# ê²½ë¡œ ì„¤ì •
DATA_PATH=/app/data
REPORTS_PATH=/app/reports
STATIC_PATH=/app/static

# ë³´ì•ˆ ì„¤ì •
SECRET_KEY=your-secret-key-here
MAX_EXECUTION_TIME=300
MAX_CODE_SIZE=10000

# Docker ì„¤ì •
DOCKER_NETWORK=report-net
EXECUTOR_MEMORY_LIMIT=4g
EXECUTOR_CPU_LIMIT=2
```

### 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
# Qwen2.5-Coder ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
python scripts/download_model.py

# ë˜ëŠ” HuggingFace CLI ì‚¬ìš©
pip install huggingface_hub
huggingface-cli download Qwen/Qwen2.5-Coder-32B-Instruct --local-dir ./models/qwen2.5-coder
```

### 4. ì„œë¹„ìŠ¤ ì‹œì‘

```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘
./scripts/start_services.sh

# ë˜ëŠ” Docker Compose ì‚¬ìš©
docker-compose up -d
```

## ğŸ’» í•µì‹¬ êµ¬í˜„ ì½”ë“œ

### 1. FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ (app/main.py)

```python
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
from .orchestrator import ReportOrchestrator

app = FastAPI(title="Report Generator API", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

class ReportRequest(BaseModel):
    user_query: str
    session_id: str = None
    data_sources: list = None

class ReportResponse(BaseModel):
    success: bool
    report_url: str = None
    error_message: str = None
    processing_time: float = None

# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”
orchestrator = ReportOrchestrator()

@app.post("/generate-report", response_model=ReportResponse)
async def generate_report(request: ReportRequest):
    """ì‚¬ìš©ì ìš”ì²­ì„ ë°›ì•„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        result = await orchestrator.process_request(
            user_query=request.user_query,
            session_id=request.session_id,
            data_sources=request.data_sources
        )
        return ReportResponse(**result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    return {"status": "healthy", "version": "1.0.0"}

@app.get("/data-sources")
async def list_data_sources():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡"""
    return orchestrator.get_available_data_sources()

if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host=os.getenv("API_HOST", "0.0.0.0"),
        port=int(os.getenv("API_PORT", 8000)),
        reload=True
    )
```

### 2. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (app/orchestrator.py)

```python
import asyncio
import time
import uuid
from typing import Dict, List, Optional
from .llm_client import QwenClient
from .data_manager import DataManager
from .code_executor import CodeExecutor
from .utils.templates import PromptTemplates

class ReportOrchestrator:
    def __init__(self):
        self.llm_client = QwenClient()
        self.data_manager = DataManager()
        self.code_executor = CodeExecutor()
        self.prompt_templates = PromptTemplates()
        
    async def process_request(
        self, 
        user_query: str, 
        session_id: Optional[str] = None,
        data_sources: Optional[List[str]] = None
    ) -> Dict:
        """ë©”ì¸ ì²˜ë¦¬ ë¡œì§"""
        start_time = time.time()
        
        try:
            # 1. ì„¸ì…˜ ID ìƒì„±
            if not session_id:
                session_id = str(uuid.uuid4())
            
            # 2. ê´€ë ¨ ë°ì´í„° ì¤€ë¹„
            context_data = await self.data_manager.prepare_context(
                user_query, data_sources
            )
            
            # 3. LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self.prompt_templates.build_generation_prompt(
                user_query=user_query,
                context_data=context_data,
                session_id=session_id
            )
            
            # 4. LLM ì‘ë‹µ ìƒì„±
            llm_response = await self.llm_client.generate_code(prompt)
            
            # 5. ì½”ë“œ ì¶”ì¶œ ë° ê²€ì¦
            extracted_code = self._extract_code_blocks(llm_response)
            
            # 6. ì½”ë“œ ì‹¤í–‰
            execution_result = await self.code_executor.execute_code(
                code=extracted_code,
                session_id=session_id,
                context_data=context_data
            )
            
            # 7. ê²°ê³¼ ì²˜ë¦¬
            if execution_result["success"]:
                report_url = f"/reports/{execution_result['report_filename']}"
                return {
                    "success": True,
                    "report_url": report_url,
                    "processing_time": time.time() - start_time
                }
            else:
                # ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ ë¡œì§
                return await self._handle_execution_error(
                    llm_response, execution_result, user_query, context_data, session_id
                )
                
        except Exception as e:
            return {
                "success": False,
                "error_message": str(e),
                "processing_time": time.time() - start_time
            }
    
    def _extract_code_blocks(self, llm_response: str) -> Dict:
        """LLM ì‘ë‹µì—ì„œ ì½”ë“œ ë¸”ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        import re
        
        # Python ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
        python_pattern = r'```python\n(.*?)\n```'
        python_matches = re.findall(python_pattern, llm_response, re.DOTALL)
        
        # HTML/JS ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
        html_pattern = r'```html\n(.*?)\n```'
        html_matches = re.findall(html_pattern, llm_response, re.DOTALL)
        
        # JavaScript ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
        js_pattern = r'```javascript\n(.*?)\n```'
        js_matches = re.findall(js_pattern, llm_response, re.DOTALL)
        
        return {
            "python_code": python_matches[0] if python_matches else None,
            "html_code": html_matches[0] if html_matches else None,
            "javascript_code": js_matches[0] if js_matches else None,
            "explanation": self._extract_explanation(llm_response)
        }
    
    def _extract_explanation(self, llm_response: str) -> str:
        """LLM ì‘ë‹µì—ì„œ ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        # ì½”ë“œ ë¸”ë¡ì´ ì•„ë‹Œ ë¶€ë¶„ì„ ì„¤ëª…ìœ¼ë¡œ ê°„ì£¼
        import re
        explanation = re.sub(r'```.*?```', '', llm_response, flags=re.DOTALL)
        return explanation.strip()
    
    async def _handle_execution_error(self, original_response, error_result, user_query, context_data, session_id):
        """ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ ë¡œì§"""
        retry_prompt = self.prompt_templates.build_error_fix_prompt(
            original_code=original_response,
            error_message=error_result["error_message"],
            user_query=user_query
        )
        
        # ì¬ì‹œë„ (ìµœëŒ€ 2íšŒ)
        for attempt in range(2):
            try:
                fixed_response = await self.llm_client.generate_code(retry_prompt)
                fixed_code = self._extract_code_blocks(fixed_response)
                
                execution_result = await self.code_executor.execute_code(
                    code=fixed_code,
                    session_id=session_id,
                    context_data=context_data
                )
                
                if execution_result["success"]:
                    report_url = f"/reports/{execution_result['report_filename']}"
                    return {"success": True, "report_url": report_url}
                    
            except Exception as e:
                continue
        
        return {
            "success": False,
            "error_message": "ì½”ë“œ ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìš”ì²­ì„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        }
    
    def get_available_data_sources(self) -> List[Dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡ ë°˜í™˜"""
        return self.data_manager.list_available_sources()
```

### 3. LLM í´ë¼ì´ì–¸íŠ¸ (app/llm_client.py)

```python
import httpx
import json
import os
from typing import Dict, List

class QwenClient:
    def __init__(self):
        self.base_url = f"http://{os.getenv('VLLM_HOST', 'localhost')}:{os.getenv('VLLM_PORT', '8001')}"
        self.model_name = os.getenv('MODEL_NAME', 'Qwen/Qwen2.5-Coder-32B-Instruct')
        
    async def generate_code(self, prompt: str, max_tokens: int = 4000) -> str:
        """Qwen2.5-Coderë¡œë¶€í„° ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        
        payload = {
            "model": self.model_name,
            "messages": [
                {
                    "role": "system",
                    "content": self._get_system_prompt()
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            "max_tokens": max_tokens,
            "temperature": 0.1,
            "top_p": 0.9,
            "stream": False
        }
        
        async with httpx.AsyncClient(timeout=300.0) as client:
            response = await client.post(
                f"{self.base_url}/v1/chat/completions",
                json=payload
            )
            response.raise_for_status()
            
            result = response.json()
            return result["choices"][0]["message"]["content"]
    
    def _get_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return """
ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ë° ì›¹ ë¦¬í¬íŠ¸ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ JSON ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , HTML/JavaScriptë¥¼ ì‚¬ìš©í•˜ì—¬ 
ì¸í„°ë™í‹°ë¸Œí•œ ì‹œê°í™” ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” Python ì½”ë“œë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ê·œì¹™:
1. ë°˜ë“œì‹œ Python ì½”ë“œì™€ HTML í…œí”Œë¦¿ì„ ìƒì„±í•˜ì„¸ìš”
2. Chart.js, D3.js, Plotly.js ë“±ì˜ ì˜¤í”„ë¼ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì„¸ìš”
3. ìƒì„±ëœ HTMLì€ ì™„ì „íˆ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
4. ëª¨ë“  ìŠ¤íƒ€ì¼ê³¼ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¡œì»¬ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
5. ë°ì´í„°ëŠ” JSON í˜•íƒœë¡œ ì œê³µë˜ë©°, ì´ë¥¼ ì ì ˆíˆ íŒŒì‹±í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”
6. ì½”ë“œëŠ” ì•ˆì „í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤

ì¶œë ¥ í˜•ì‹:
- Python ì½”ë“œ: ```python ... ```
- HTML ì½”ë“œ: ```html ... ```
- JavaScript ì½”ë“œ (í•„ìš”ì‹œ): ```javascript ... ```
- ì„¤ëª…: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±

ìƒì„±ëœ ë¦¬í¬íŠ¸ëŠ” `/reports/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
"""

    async def health_check(self) -> bool:
        """vLLM ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(f"{self.base_url}/health")
                return response.status_code == 200
        except:
            return False
```

### 4. ì½”ë“œ ì‹¤í–‰ í™˜ê²½ (app/code_executor.py)

```python
import docker
import tempfile
import os
import json
import asyncio
from typing import Dict, Any
import uuid

class CodeExecutor:
    def __init__(self):
        self.docker_client = docker.from_env()
        self.network_name = os.getenv('DOCKER_NETWORK', 'report-net')
        self.reports_path = os.getenv('REPORTS_PATH', '/app/reports')
        
    async def execute_code(
        self, 
        code: Dict[str, str], 
        session_id: str, 
        context_data: Dict[str, Any]
    ) -> Dict:
        """ê²©ë¦¬ëœ í™˜ê²½ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        
        try:
            # ì„ì‹œ ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
            with tempfile.TemporaryDirectory() as temp_dir:
                
                # 1. ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ì €ì¥
                data_file = os.path.join(temp_dir, 'context_data.json')
                with open(data_file, 'w', encoding='utf-8') as f:
                    json.dump(context_data, f, ensure_ascii=False, indent=2)
                
                # 2. Python ì½”ë“œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
                if code.get('python_code'):
                    python_script = self._create_python_script(
                        code['python_code'], 
                        session_id,
                        code.get('html_code'),
                        code.get('javascript_code')
                    )
                    
                    script_file = os.path.join(temp_dir, 'execute.py')
                    with open(script_file, 'w', encoding='utf-8') as f:
                        f.write(python_script)
                
                # 3. Docker ì»¨í…Œì´ë„ˆì—ì„œ ì‹¤í–‰
                result = await self._run_in_container(temp_dir, session_id)
                
                return result
                
        except Exception as e:
            return {
                "success": False,
                "error_message": f"ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
    
    def _create_python_script(
        self, 
        python_code: str, 
        session_id: str,
        html_template: str = None,
        js_code: str = None
    ) -> str:
        """ì‹¤í–‰í•  Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        
        script_template = f"""
import json
import os
import sys
from datetime import datetime

# ì•ˆì „í•œ ì‹¤í–‰ì„ ìœ„í•œ ì œí•œëœ í™˜ê²½
__builtins__ = {{
    'print': print,
    'len': len,
    'str': str,
    'int': int,
    'float': float,
    'list': list,
    'dict': dict,
    'json': json,
    'open': open,
    'range': range,
    'enumerate': enumerate,
    'zip': zip,
    'max': max,
    'min': min,
    'sum': sum,
    'sorted': sorted,
    'round': round
}}

# ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
try:
    with open('/workspace/context_data.json', 'r', encoding='utf-8') as f:
        context_data = json.load(f)
    print("ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {{e}}")
    context_data = {{}}

# ì„¸ì…˜ ì •ë³´
SESSION_ID = "{session_id}"
REPORT_FILENAME = f"report_{{SESSION_ID}}.html"
REPORTS_PATH = "/reports"

# HTML í…œí”Œë¦¿
HTML_TEMPLATE = '''{html_template or ""}'''

# JavaScript ì½”ë“œ
JS_CODE = '''{js_code or ""}'''

# ì‚¬ìš©ì ì •ì˜ ì½”ë“œ ì‹¤í–‰
try:
{python_code}
    
    print(f"ë¦¬í¬íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {{REPORT_FILENAME}}")
    
except Exception as e:
    print(f"ì˜¤ë¥˜ ë°œìƒ: {{e}}")
    sys.exit(1)
"""
        
        return script_template
    
    async def _run_in_container(self, workspace_dir: str, session_id: str) -> Dict:
        """Docker ì»¨í…Œì´ë„ˆì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        
        container_name = f"executor_{session_id}"
        
        try:
            # ì»¨í…Œì´ë„ˆ ì‹¤í–‰
            container = self.docker_client.containers.run(
                image="report-executor:latest",
                name=container_name,
                detach=True,
                remove=True,
                network=self.network_name,
                volumes={
                    workspace_dir: {'bind': '/workspace', 'mode': 'rw'},
                    self.reports_path: {'bind': '/reports', 'mode': 'rw'},
                    '/app/static': {'bind': '/static', 'mode': 'ro'}
                },
                environment={
                    'PYTHONPATH': '/workspace',
                    'SESSION_ID': session_id
                },
                command="python /workspace/execute.py",
                mem_limit=os.getenv('EXECUTOR_MEMORY_LIMIT', '4g'),
                cpu_count=int(os.getenv('EXECUTOR_CPU_LIMIT', '2')),
                security_opt=['no-new-privileges'],
                cap_drop=['ALL']
            )
            
            # ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
            result = container.wait(timeout=int(os.getenv('MAX_EXECUTION_TIME', '300')))
            
            # ë¡œê·¸ ìˆ˜ì§‘
            logs = container.logs().decode('utf-8')
            
            if result['StatusCode'] == 0:
                return {
                    "success": True,
                    "report_filename": f"report_{session_id}.html",
                    "logs": logs
                }
            else:
                return {
                    "success": False,
                    "error_message": f"ì‹¤í–‰ ì‹¤íŒ¨ (ì½”ë“œ: {result['StatusCode']})",
                    "logs": logs
                }
                
        except docker.errors.ContainerError as e:
            return {
                "success": False,
                "error_message": f"ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"
            }
        except Exception as e:
            return {
                "success": False,
                "error_message": f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
            }
        finally:
            # ì»¨í…Œì´ë„ˆ ì •ë¦¬
            try:
                container = self.docker_client.containers.get(container_name)
                container.remove(force=True)
            except:
                pass
```

### 5. ë°ì´í„° ë§¤ë‹ˆì € (app/data_manager.py)

```python
import json
import os
import glob
from typing import Dict, List, Any, Optional
import fnmatch

class DataManager:
    def __init__(self):
        self.data_path = os.getenv('DATA_PATH', '/app/data')
        self.mcp_bundles_path = os.path.join(self.data_path, 'mcp_bundles')
        
    async def prepare_context(
        self, 
        user_query: str, 
        requested_sources: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì ìš”ì²­ì— ë§ëŠ” ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤."""
        
        # 1. ì‚¬ìš©ì ìš”ì²­ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ë°ì´í„° ì†ŒìŠ¤ ì‹ë³„
        relevant_sources = self._identify_relevant_sources(user_query, requested_sources)
        
        # 2. ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
        context_data = {}
        for source in relevant_sources:
            try:
                data = self._load_data_bundle(source)
                context_data[source] = data
            except Exception as e:
                print(f"ë°ì´í„° ì†ŒìŠ¤ '{source}' ë¡œë“œ ì‹¤íŒ¨: {e}")
                
        # 3. ë©”íƒ€ë°ì´í„° ì¶”ê°€
        context_data['_metadata'] = {
            'query': user_query,
            'sources_loaded': list(context_data.keys()),
            'total_records': sum(len(v) if isinstance(v, list) else 1 for v in context_data.values() if not v.startswith('_'))
        }
        
        return context_data
    
    def _identify_relevant_sources(
        self, 
        user_query: str, 
        requested_sources: Optional[List[str]] = None
    ) -> List[str]:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        
        # ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­ëœ ì†ŒìŠ¤ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        if requested_sources:
            return requested_sources
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­
        available_sources = self.list_available_sources()
        relevant_sources = []
        
        query_lower = user_query.lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ê·œì¹™
        keyword_mapping = {
            'sales': ['sales_data', 'revenue_data'],
            'user': ['user_analytics', 'user_behavior'],
            'finance': ['financial_reports', 'budget_data'],
            'marketing': ['marketing_campaigns', 'ad_performance'],
            'product': ['product_analytics', 'inventory_data'],
            'traffic': ['web_analytics', 'user_analytics'],
            'conversion': ['conversion_data', 'funnel_analytics']
        }
        
        for keyword, sources in keyword_mapping.items():
            if keyword in query_lower:
                for source in sources:
                    if any(s['name'] == source for s in available_sources):
                        relevant_sources.append(source)
        
        # ë§¤ì¹­ë˜ëŠ” ì†ŒìŠ¤ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì†ŒìŠ¤ ì‚¬ìš©
        if not relevant_sources and available_sources:
            relevant_sources = [available_sources[0]['name']]
        
        return list(set(relevant_sources))  # ì¤‘ë³µ ì œê±°
    
    def _load_data_bundle(self, source_name: str) -> Any:
        """íŠ¹ì • ë°ì´í„° ë²ˆë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        
        bundle_file = os.path.join(self.mcp_bundles_path, f"{source_name}.json")
        
        if not os.path.exists(bundle_file):
            raise FileNotFoundError(f"ë°ì´í„° ë²ˆë“¤ '{source_name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        with open(bundle_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def list_available_sources(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        
        sources = []
        
        # JSON íŒŒì¼ë“¤ì„ ìŠ¤ìº”
        pattern = os.path.join(self.mcp_bundles_path, "*.json")
        
        for file_path in glob.glob(pattern):
            source_name = os.path.splitext(os.path.basename(file_path))[0]
            
            try:
                # íŒŒì¼ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ë°ì´í„° êµ¬ì¡° ë¶„ì„
                record_count = len(data) if isinstance(data, list) else 1
                
                sources.append({
                    'name': source_name,
                    'file_path': file_path,
                    'record_count': record_count,
                    'size_mb': round(os.path.getsize(file_path) / 1024 / 1024, 2),
                    'description': self._generate_description(source_name, data)
                })
                
            except Exception as e:
                print(f"ì†ŒìŠ¤ '{source_name}' ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return sorted(sources, key=lambda x: x['name'])
    
    def _generate_description(self, source_name: str, data: Any) -> str:
        """ë°ì´í„° ì†ŒìŠ¤ì— ëŒ€í•œ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        
        if isinstance(data, list) and data:
            sample = data[0]
            if isinstance(sample, dict):
                keys = list(sample.keys())[:5]  # ì²˜ìŒ 5ê°œ í‚¤ë§Œ
                return f"{len(data)}ê°œ ë ˆì½”ë“œ, ì£¼ìš” í•„ë“œ: {', '.join(keys)}"
        
        return f"ë°ì´í„° íƒ€ì…: {type(data).__name__}"
```

### 6. Docker ì„¤ì •

#### docker-compose.yml

```yaml
version: '3.8'

services:
  # vLLM ì„œë¹™ ì„œë²„
  vllm-server:
    image: vllm/vllm-openai:latest
    container_name: vllm-server
    ports:
      - "${VLLM_PORT:-8001}:8000"
    volumes:
      - ./models:/models
      - ./cache:/root/.cache
    environment:
      - CUDA_VISIBLE_DEVICES=0
    command: >
      --model /models/qwen2.5-coder
      --served-model-name ${MODEL_NAME}
      --host 0.0.0.0
      --port 8000
      --gpu-memory-utilization ${GPU_MEMORY_UTILIZATION:-0.8}
      --max-model-len 32768
      --dtype auto
      --api-key ${VLLM_API_KEY:-your-api-key}
    networks:
      - report-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
  app:
    build:
      context: .
      dockerfile: docker/app.Dockerfile
    container_name: report-app
    ports:
      - "${API_PORT:-8000}:8000"
    volumes:
      - ./data:/app/data:ro
      - ./reports:/app/reports:rw
      - ./static:/app/static:ro
      - ./templates:/app/templates:ro
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - VLLM_HOST=vllm-server
      - VLLM_PORT=8000
      - DATA_PATH=/app/data
      - REPORTS_PATH=/app/reports
      - STATIC_PATH=/app/static
    depends_on:
      - vllm-server
    networks:
      - report-net

  # Nginx ì›¹ì„œë²„
  nginx:
    build:
      context: .
      dockerfile: docker/nginx.Dockerfile
    container_name: report-nginx
    ports:
      - "${NGINX_PORT:-80}:80"
    volumes:
      - ./reports:/usr/share/nginx/html/reports:ro
      - ./static:/usr/share/nginx/html/static:ro
      - ./config/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app
    networks:
      - report-net

  # ì½”ë“œ ì‹¤í–‰ í™˜ê²½ (ë² ì´ìŠ¤ ì´ë¯¸ì§€)
  executor:
    build:
      context: .
      dockerfile: docker/executor.Dockerfile
    image: report-executor:latest
    container_name: report-executor-base
    profiles: ["build-only"]  # ì§ì ‘ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
    networks:
      - report-net

networks:
  report-net:
    driver: bridge

volumes:
  model-cache:
```

#### docker/app.Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    docker.io \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY app/ ./app/
COPY templates/ ./templates/
COPY static/ ./static/

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### docker/executor.Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /workspace

# ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
RUN pip install --no-cache-dir \
    pandas \
    numpy \
    matplotlib \
    seaborn \
    plotly \
    jinja2 \
    beautifulsoup4

# ë³´ì•ˆ ì„¤ì •
RUN useradd -m -s /bin/bash executor
USER executor

# ê¸°ë³¸ ì‹¤í–‰ ëª…ë ¹
CMD ["python", "/workspace/execute.py"]
```

#### docker/nginx.Dockerfile

```dockerfile
FROM nginx:alpine

# Nginx ì„¤ì • íŒŒì¼ ë³µì‚¬
COPY config/nginx.conf /etc/nginx/nginx.conf

# ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ ìƒì„±
RUN mkdir -p /usr/share/nginx/html/reports \
    && mkdir -p /usr/share/nginx/html/static

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

### 7. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (app/utils/templates.py)

```python
from typing import Dict, Any, List

class PromptTemplates:
    
    @staticmethod
    def build_generation_prompt(
        user_query: str, 
        context_data: Dict[str, Any], 
        session_id: str
    ) -> str:
        """ë¦¬í¬íŠ¸ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        
        # ë°ì´í„° ìƒ˜í”Œ ì¤€ë¹„
        data_preview = PromptTemplates._prepare_data_preview(context_data)
        
        prompt = f"""
ì‚¬ìš©ì ìš”ì²­: {user_query}

ì œê³µëœ ë°ì´í„°:
{data_preview}

ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ì›¹ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:

1. **Python ì½”ë“œ ì‘ì„±**:
   - JSON ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì²˜ë¦¬
   - HTML íŒŒì¼ì„ ìƒì„±í•˜ì—¬ /reports/report_{session_id}.htmlì— ì €ì¥
   - ì°¨íŠ¸ ë°ì´í„°ë¥¼ JavaScript í˜•íƒœë¡œ ì¤€ë¹„

2. **HTML ë¦¬í¬íŠ¸ êµ¬ì¡°**:
   - ì œëª©ê³¼ ìš”ì•½
   - ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜
   - ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸ (Chart.js ì‚¬ìš©)
   - ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

3. **ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­**:
   - Chart.jsëŠ” /static/js/chart.min.js ê²½ë¡œ ì‚¬ìš©
   - ì™„ì „í•œ ì˜¤í”„ë¼ì¸ ë™ì‘
   - ëª¨ë°”ì¼ ë°˜ì‘í˜• ë””ìì¸
   - ì ‘ê·¼ì„± ê³ ë ¤

4. **ë³´ì•ˆ ê³ ë ¤ì‚¬í•­**:
   - ì•ˆì „í•œ íŒŒì¼ ê²½ë¡œë§Œ ì‚¬ìš©
   - XSS ë°©ì§€ë¥¼ ìœ„í•œ ë°ì´í„° ì´ìŠ¤ì¼€ì´í•‘

ì˜ˆì‹œ ì¶œë ¥ í˜•ì‹:

```python
import json
import os
from datetime import datetime

# ë°ì´í„° ë¡œë“œ ë° ë¶„ì„
# ... ë¶„ì„ ë¡œì§ ...

# HTML ë¦¬í¬íŠ¸ ìƒì„±
html_content = '''
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸</title>
    <script src="/static/js/chart.min.js"></script>
    <style>
        /* ìŠ¤íƒ€ì¼ ì •ì˜ */
    </style>
</head>
<body>
    <!-- ë¦¬í¬íŠ¸ ë‚´ìš© -->
</body>
</html>
'''

# íŒŒì¼ ì €ì¥
with open(f'/reports/report_{SESSION_ID}.html', 'w', encoding='utf-8') as f:
    f.write(html_content)
```

ì‹¤ì œ êµ¬í˜„ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.
"""
        
        return prompt
    
    @staticmethod
    def build_error_fix_prompt(
        original_code: str, 
        error_message: str, 
        user_query: str
    ) -> str:
        """ì˜¤ë¥˜ ìˆ˜ì •ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        
        return f"""
ì´ì „ ì½”ë“œ ì‹¤í–‰ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

ì›ë³¸ ì‚¬ìš©ì ìš”ì²­: {user_query}

ì´ì „ ìƒì„±ëœ ì½”ë“œ:
{original_code}

ë°œìƒí•œ ì˜¤ë¥˜:
{error_message}

ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ì •ìƒ ë™ì‘í•˜ëŠ” ì½”ë“œë¥¼ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”. 
íŠ¹íˆ ë‹¤ìŒ ì‚¬í•­ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”:

1. íŒŒì¼ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
2. ë°ì´í„° êµ¬ì¡°ì™€ í‚¤ê°€ ì‹¤ì œ ë°ì´í„°ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
3. HTML/JavaScript ë¬¸ë²• ì˜¤ë¥˜ê°€ ì—†ëŠ”ì§€ í™•ì¸
4. ë³´ì•ˆ ì œì•½ì‚¬í•­ì„ ì¤€ìˆ˜í–ˆëŠ”ì§€ í™•ì¸

ìˆ˜ì •ëœ ì½”ë“œ:
"""

    @staticmethod  
    def _prepare_data_preview(context_data: Dict[str, Any]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        
        preview_lines = []
        
        for source_name, data in context_data.items():
            if source_name.startswith('_'):
                continue
                
            preview_lines.append(f"**{source_name}**:")
            
            if isinstance(data, list) and data:
                preview_lines.append(f"  - ë ˆì½”ë“œ ìˆ˜: {len(data)}")
                
                # ì²« ë²ˆì§¸ ë ˆì½”ë“œì˜ êµ¬ì¡° í‘œì‹œ
                sample = data[0]
                if isinstance(sample, dict):
                    preview_lines.append("  - í•„ë“œ êµ¬ì¡°:")
                    for key, value in list(sample.items())[:5]:
                        preview_lines.append(f"    â€¢ {key}: {type(value).__name__}")
                        
            elif isinstance(data, dict):
                preview_lines.append(f"  - í‚¤ ê°œìˆ˜: {len(data)}")
                preview_lines.append("  - ì£¼ìš” í‚¤:")
                for key in list(data.keys())[:5]:
                    preview_lines.append(f"    â€¢ {key}")
                    
            preview_lines.append("")
        
        return "\n".join(preview_lines)
```

## ğŸ”§ ì„¤ì • íŒŒì¼ë“¤

### config/nginx.conf

```nginx
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    sendfile on;
    keepalive_timeout 65;
    
    # ë³´ì•ˆ í—¤ë”
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    
    server {
        listen 80;
        server_name localhost;
        
        # ì •ì  íŒŒì¼ ì„œë¹™
        location /static/ {
            alias /usr/share/nginx/html/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
        
        # ë¦¬í¬íŠ¸ íŒŒì¼ ì„œë¹™
        location /reports/ {
            alias /usr/share/nginx/html/reports/;
            expires 1h;
            add_header Cache-Control "public";
        }
        
        # API í”„ë¡ì‹œ
        location /api/ {
            proxy_pass http://app:8000;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
        
        # ê¸°ë³¸ í˜ì´ì§€
        location / {
            return 301 /static/index.html;
        }
    }
}
```

### requirements.txt

```txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
httpx==0.25.2
docker==6.1.3
jinja2==3.1.2
python-multipart==0.0.6
python-dotenv==1.0.0
aiofiles==23.2.1
pandas==2.1.3
numpy==1.25.2
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. ì„œë¹„ìŠ¤ ì‹œì‘

```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# ë¡œê·¸ í™•ì¸
docker-compose logs -f app
```

### 2. ë°ì´í„° ì¤€ë¹„

```bash
# MCP ë°ì´í„° ë²ˆë“¤ ì˜ˆì‹œ ìƒì„±
mkdir -p data/mcp_bundles

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
cat > data/mcp_bundles/sales_data.json << 'EOF'
[
  {
    "date": "2024-01-01",
    "product": "Product A",
    "sales": 1500,
    "revenue": 45000,
    "region": "Seoul"
  },
  {
    "date": "2024-01-01", 
    "product": "Product B",
    "sales": 800,
    "revenue": 32000,
    "region": "Busan"
  }
]
EOF
```

### 3. API í˜¸ì¶œ ì˜ˆì‹œ

```bash
# ë¦¬í¬íŠ¸ ìƒì„± ìš”ì²­
curl -X POST "http://localhost:8000/generate-report" \
  -H "Content-Type: application/json" \
  -d '{
    "user_query": "ì§€ë‚œ ë‹¬ ì œí’ˆë³„ ë§¤ì¶œ í˜„í™©ì„ ì°¨íŠ¸ë¡œ ë³´ì—¬ì£¼ì„¸ìš”",
    "session_id": "test123",
    "data_sources": ["sales_data"]
  }'

# ì‘ë‹µ ì˜ˆì‹œ
{
  "success": true,
  "report_url": "/reports/report_test123.html",
  "processing_time": 15.3
}
```

### 4. ì›¹ ì¸í„°í˜ì´ìŠ¤

`static/index.html` íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¸í„°í˜ì´ìŠ¤ ì œê³µ:

```html
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI ë¦¬í¬íŠ¸ ìƒì„±ê¸°</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
        .input-area { margin-bottom: 20px; }
        textarea { width: 100%; height: 100px; padding: 10px; }
        button { background: #007bff; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; }
        .result { margin-top: 20px; padding: 15px; background: #f8f9fa; border-radius: 5px; }
    </style>
</head>
<body>
    <h1>ğŸ¤– AI ë¦¬í¬íŠ¸ ìƒì„±ê¸°</h1>
    
    <div class="input-area">
        <label for="query">ìš”ì²­ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”:</label>
        <textarea id="query" placeholder="ì˜ˆ: ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ í˜„í™©ì„ ì°¨íŠ¸ë¡œ ë³´ì—¬ì£¼ì„¸ìš”"></textarea>
        <button onclick="generateReport()">ë¦¬í¬íŠ¸ ìƒì„±</button>
    </div>
    
    <div id="result" class="result" style="display:none;"></div>

    <script>
        async function generateReport() {
            const query = document.getElementById('query').value;
            const resultDiv = document.getElementById('result');
            
            if (!query.trim()) {
                alert('ìš”ì²­ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.');
                return;
            }
            
            resultDiv.style.display = 'block';
            resultDiv.innerHTML = 'ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...';
            
            try {
                const response = await fetch('/api/generate-report', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        user_query: query,
                        session_id: 'web_' + Date.now()
                    })
                });
                
                const result = await response.json();
                
                if (result.success) {
                    resultDiv.innerHTML = `
                        <h3>âœ… ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!</h3>
                        <p>ì²˜ë¦¬ ì‹œê°„: ${result.processing_time.toFixed(1)}ì´ˆ</p>
                        <a href="${result.report_url}" target="_blank" style="display: inline-block; background: #28a745; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px;">ë¦¬í¬íŠ¸ ë³´ê¸°</a>
                    `;
                } else {
                    resultDiv.innerHTML = `<h3>âŒ ì˜¤ë¥˜ ë°œìƒ</h3><p>${result.error_message}</p>`;
                }
            } catch (error) {
                resultDiv.innerHTML = `<h3>âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜</h3><p>${error.message}</p>`;
            }
        }
    </script>
</body>
</html>
```

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 1. ì½”ë“œ ì‹¤í–‰ í™˜ê²½ ê²©ë¦¬
- Docker ì»¨í…Œì´ë„ˆë¡œ ì™„ì „ ê²©ë¦¬
- ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ ì°¨ë‹¨
- íŒŒì¼ì‹œìŠ¤í…œ ì ‘ê·¼ ì œí•œ
- ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì œí•œ

### 2. ì…ë ¥ ê²€ì¦
```python
# app/utils/security.py
import re
from typing import List

class SecurityValidator:
    
    @staticmethod
    def validate_user_query(query: str) -> bool:
        """ì‚¬ìš©ì ì¿¼ë¦¬ì˜ ì•ˆì „ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
        
        # ê¸¸ì´ ì œí•œ
        if len(query) > 1000:
            return False
        
        # ìœ„í—˜í•œ í‚¤ì›Œë“œ í•„í„°ë§
        dangerous_keywords = [
            'import os', 'import sys', 'subprocess', 
            'eval(', 'exec(', '__import__',
            'file://', 'http://', 'https://'
        ]
        
        query_lower = query.lower()
        for keyword in dangerous_keywords:
            if keyword in query_lower:
                return False
        
        return True
    
    @staticmethod
    def sanitize_filename(filename: str) -> str:
        """íŒŒì¼ëª…ì„ ì•ˆì „í•˜ê²Œ ì •ë¦¬í•©ë‹ˆë‹¤."""
        
        # ì•ŒíŒŒë²³, ìˆ«ì, í•˜ì´í”ˆ, ì–¸ë”ìŠ¤ì½”ì–´ë§Œ í—ˆìš©
        sanitized = re.sub(r'[^a-zA-Z0-9_-]', '', filename)
        
        # ê¸¸ì´ ì œí•œ
        return sanitized[:50]
```

### 3. íŒŒì¼ ì‹œìŠ¤í…œ ë³´ì•ˆ
```python
# ì•ˆì „í•œ ê²½ë¡œ ê²€ì¦
def validate_file_path(path: str, allowed_base: str) -> bool:
    """íŒŒì¼ ê²½ë¡œê°€ í—ˆìš©ëœ ë””ë ‰í† ë¦¬ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    
    import os
    
    try:
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        abs_path = os.path.abspath(path)
        abs_base = os.path.abspath(allowed_base)
        
        # ê³µí†µ ê²½ë¡œ í™•ì¸
        return os.path.commonpath([abs_path, abs_base]) == abs_base
    
    except (ValueError, OSError):
        return False
```

## ğŸ”„ í™•ì¥ ê°€ëŠ¥ì„±

### 1. ë‹¤ì–‘í•œ ì°¨íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì›
- D3.js ê³ ê¸‰ ì‹œê°í™”
- Plotly.js ê³¼í•™ì  ì°¨íŠ¸
- Three.js 3D ì‹œê°í™”

### 2. ì¶”ê°€ ë°ì´í„° ì†ŒìŠ¤
- ì‹¤ì‹œê°„ API ì—°ë™
- ë°ì´í„°ë² ì´ìŠ¤ ì§ì ‘ ì—°ê²°
- íŒŒì¼ ì—…ë¡œë“œ ì§€ì›

### 3. ê³ ê¸‰ ê¸°ëŠ¥
- ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œ
- ë¦¬í¬íŠ¸ ë²„ì „ ê´€ë¦¬
- ì´ë©”ì¼ ìë™ ë°œì†¡
- PDF ë‚´ë³´ë‚´ê¸°

### 4. ì„±ëŠ¥ ìµœì í™”
- Redis ìºì‹±
- ë¹„ë™ê¸° í ì‹œìŠ¤í…œ
- GPU ë©”ëª¨ë¦¬ ìµœì í™”
- ë¶„ì‚° ì²˜ë¦¬

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **GPU ë©”ëª¨ë¦¬ ë¶€ì¡±**
```bash
# GPU ì‚¬ìš©ëŸ‰ í™•ì¸
nvidia-smi

# vLLM ë©”ëª¨ë¦¬ ì„¤ì • ì¡°ì •
# .envì—ì„œ GPU_MEMORY_UTILIZATION ê°’ì„ 0.7ë¡œ ë‚®ì¶¤
```

2. **Docker ê¶Œí•œ ë¬¸ì œ**
```bash
# Docker ê·¸ë£¹ì— ì‚¬ìš©ì ì¶”ê°€
sudo usermod -aG docker $USER
sudo systemctl restart docker
```

3. **í¬íŠ¸ ì¶©ëŒ**
```bash
# ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ í™•ì¸
sudo netstat -tulpn | grep :8000

# .envì—ì„œ í¬íŠ¸ ë²ˆí˜¸ ë³€ê²½
```

### ë¡œê·¸ í™•ì¸

```bash
# ì „ì²´ ì„œë¹„ìŠ¤ ë¡œê·¸
docker-compose logs

# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸
docker-compose logs app
docker-compose logs vllm-server

# ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
docker-compose logs -f
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. vLLM ìµœì í™”
```bash
# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¡°ì •
export GPU_MEMORY_UTILIZATION=0.8

# ë°°ì¹˜ í¬ê¸° ìµœì í™”
export MAX_NUM_SEQS=256

# KV ìºì‹œ ìµœëŒ€ í† í° ìˆ˜
export MAX_MODEL_LEN=8192
```

### 2. ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ìµœì í™”
```yaml
# docker-compose.ymlì—ì„œ ë¦¬ì†ŒìŠ¤ ì œí•œ
services:
  executor:
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
```

### 3. ìºì‹± ì „ëµ
```python
# app/utils/cache.py
import asyncio
from functools import wraps
from typing import Dict, Any

class ReportCache:
    def __init__(self):
        self._cache: Dict[str, Any] = {}
        self._max_size = 100
    
    def get_cache_key(self, user_query: str, data_sources: list) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        import hashlib
        key_data = f"{user_query}:{','.join(sorted(data_sources or []))}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    async def get(self, key: str) -> Any:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        return self._cache.get(key)
    
    async def set(self, key: str, value: Any):
        """ìºì‹œì— ê°’ ì €ì¥"""
        if len(self._cache) >= self._max_size:
            # LRU ë°©ì‹ìœ¼ë¡œ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = next(iter(self._cache))
            del self._cache[oldest_key]
        
        self._cache[key] = value
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/test_data_manager.py
import pytest
from app.data_manager import DataManager

@pytest.fixture
def data_manager():
    return DataManager()

@pytest.mark.asyncio
async def test_prepare_context(data_manager):
    """ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ í…ŒìŠ¤íŠ¸"""
    
    query = "ë§¤ì¶œ í˜„í™©ì„ ë³´ì—¬ì£¼ì„¸ìš”"
    context = await data_manager.prepare_context(query)
    
    assert isinstance(context, dict)
    assert '_metadata' in context
    assert 'query' in context['_metadata']
```

### 2. í†µí•© í…ŒìŠ¤íŠ¸
```python
# tests/test_integration.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_generate_report_endpoint():
    """ë¦¬í¬íŠ¸ ìƒì„± API í…ŒìŠ¤íŠ¸"""
    
    response = client.post("/generate-report", json={
        "user_query": "í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”",
        "session_id": "test123"
    })
    
    assert response.status_code == 200
    data = response.json()
    assert data["success"] is True
    assert "report_url" in data
```

### 3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
```python
# tests/test_performance.py
import time
import asyncio
from app.orchestrator import ReportOrchestrator

async def test_response_time():
    """ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸"""
    
    orchestrator = ReportOrchestrator()
    
    start_time = time.time()
    result = await orchestrator.process_request(
        user_query="ê°„ë‹¨í•œ ì°¨íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”",
        session_id="perf_test"
    )
    end_time = time.time()
    
    response_time = end_time - start_time
    assert response_time < 30.0  # 30ì´ˆ ì´ë‚´ ì‘ë‹µ
    assert result["success"] is True
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### 1. ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
```python
# app/monitoring.py
import psutil
import time
from typing import Dict

class SystemMonitor:
    
    @staticmethod
    def get_system_metrics() -> Dict:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        return {
            "cpu_percent": psutil.cpu_percent(),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_percent": psutil.disk_usage('/').percent,
            "timestamp": time.time()
        }
    
    @staticmethod
    def get_gpu_metrics() -> Dict:
        """GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (nvidia-smi í•„ìš”)"""
        
        try:
            import subprocess
            result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', '--format=csv,nounits,noheader'], 
                                 capture_output=True, text=True)
            
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                gpu_data = []
                
                for i, line in enumerate(lines):
                    parts = line.split(', ')
                    gpu_data.append({
                        "gpu_id": i,
                        "utilization": float(parts[0]),
                        "memory_used": float(parts[1]),
                        "memory_total": float(parts[2])
                    })
                
                return {"gpus": gpu_data}
                
        except Exception as e:
            return {"error": str(e)}
        
        return {"gpus": []}
```

### 2. ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­
```python
# app/metrics.py
from collections import defaultdict
import time

class ApplicationMetrics:
    def __init__(self):
        self.request_count = defaultdict(int)
        self.response_times = []
        self.error_count = 0
        self.success_count = 0
    
    def record_request(self, endpoint: str):
        """ìš”ì²­ ê¸°ë¡"""
        self.request_count[endpoint] += 1
    
    def record_response_time(self, duration: float):
        """ì‘ë‹µ ì‹œê°„ ê¸°ë¡"""
        self.response_times.append(duration)
        
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        if len(self.response_times) > 100:
            self.response_times.pop(0)
    
    def record_success(self):
        """ì„±ê³µ ì‘ë‹µ ê¸°ë¡"""
        self.success_count += 1
    
    def record_error(self):
        """ì˜¤ë¥˜ ì‘ë‹µ ê¸°ë¡"""
        self.error_count += 1
    
    def get_metrics(self) -> dict:
        """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        avg_response_time = sum(self.response_times) / len(self.response_times) if self.response_times else 0
        
        return {
            "total_requests": sum(self.request_count.values()),
            "success_count": self.success_count,
            "error_count": self.error_count,
            "average_response_time": avg_response_time,
            "requests_by_endpoint": dict(self.request_count)
        }
```

## ğŸ“ ì¶”ê°€ ìŠ¤í¬ë¦½íŠ¸

### scripts/setup.sh
```bash
#!/bin/bash

echo "ğŸš€ Report Generator ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤..."

# 1. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
if [ ! -f .env ]; then
    echo "âŒ .env íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. .env.exampleì„ ë³µì‚¬í•˜ì—¬ ì„¤ì •í•˜ì„¸ìš”."
    exit 1
fi

# 2. ë””ë ‰í† ë¦¬ ìƒì„±
echo "ğŸ“ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤..."
mkdir -p data/mcp_bundles
mkdir -p data/schemas
mkdir -p reports
mkdir -p static/js
mkdir -p static/css
mkdir -p static/fonts
mkdir -p models
mkdir -p cache

# 3. Chart.js ë‹¤ìš´ë¡œë“œ
echo "ğŸ“Š Chart.jsë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤..."
curl -L https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.min.js -o static/js/chart.min.js

# 4. D3.js ë‹¤ìš´ë¡œë“œ  
echo "ğŸ“ˆ D3.jsë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤..."
curl -L https://d3js.org/d3.v7.min.js -o static/js/d3.min.js

# 5. Plotly.js ë‹¤ìš´ë¡œë“œ
echo "ğŸ“‰ Plotly.jsë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤..."
curl -L https://cdn.plot.ly/plotly-2.27.0.min.js -o static/js/plotly.min.js

# 6. ê¸°ë³¸ CSS ìƒì„±
echo "ğŸ¨ ê¸°ë³¸ ìŠ¤íƒ€ì¼ì„ ìƒì„±í•©ë‹ˆë‹¤..."
cat > static/css/report.css << 'EOF'
/* ë¦¬í¬íŠ¸ ê¸°ë³¸ ìŠ¤íƒ€ì¼ */
body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    margin: 0;
    padding: 20px;
    background-color: #f8f9fa;
}

.report-container {
    max-width: 1200px;
    margin: 0 auto;
    background: white;
    border-radius: 8px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    padding: 30px;
}

.report-title {
    color: #2c3e50;
    border-bottom: 3px solid #3498db;
    padding-bottom: 10px;
    margin-bottom: 30px;
}

.chart-container {
    margin: 30px 0;
    padding: 20px;
    background: #fafafa;
    border-radius: 6px;
    border-left: 4px solid #3498db;
}

.insight-box {
    background: #e8f5e8;
    border: 1px solid #d4edda;
    border-radius: 6px;
    padding: 15px;
    margin: 20px 0;
}

.metric-card {
    display: inline-block;
    background: white;
    border: 1px solid #dee2e6;
    border-radius: 6px;
    padding: 20px;
    margin: 10px;
    min-width: 150px;
    text-align: center;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
}

.metric-value {
    font-size: 2em;
    font-weight: bold;
    color: #2980b9;
}

.metric-label {
    color: #7f8c8d;
    margin-top: 5px;
}

@media (max-width: 768px) {
    .report-container {
        padding: 15px;
    }
    
    .metric-card {
        display: block;
        margin: 10px 0;
    }
}
EOF

# 7. ìƒ˜í”Œ ë°ì´í„° ìƒì„±
echo "ğŸ“Š ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤..."
cat > data/mcp_bundles/sales_data.json << 'EOF'
[
  {
    "date": "2024-01-01",
    "product": "Product A",
    "sales": 1500,
    "revenue": 45000,
    "region": "Seoul",
    "category": "Electronics"
  },
  {
    "date": "2024-01-01",
    "product": "Product B", 
    "sales": 800,
    "revenue": 32000,
    "region": "Busan",
    "category": "Clothing"
  },
  {
    "date": "2024-02-01",
    "product": "Product A",
    "sales": 1800,
    "revenue": 54000,
    "region": "Seoul",
    "category": "Electronics"
  },
  {
    "date": "2024-02-01",
    "product": "Product B",
    "sales": 950,
    "revenue": 38000,
    "region": "Busan", 
    "category": "Clothing"
  }
]
EOF

echo "âœ… ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
echo "ğŸ”§ ë‹¤ìŒ ë‹¨ê³„: docker-compose up -d ì‹¤í–‰"
```

### scripts/start_services.sh
```bash
#!/bin/bash

echo "ğŸš€ Report Generator ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤..."

# 1. í™˜ê²½ í™•ì¸
./scripts/setup.sh

# 2. Docker ë„¤íŠ¸ì›Œí¬ ìƒì„±
echo "ğŸŒ Docker ë„¤íŠ¸ì›Œí¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤..."
docker network create report-net 2>/dev/null || echo "ë„¤íŠ¸ì›Œí¬ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."

# 3. ì´ë¯¸ì§€ ë¹Œë“œ
echo "ğŸ—ï¸ Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤..."
docker-compose build

# 4. ì„œë¹„ìŠ¤ ì‹œì‘
echo "â–¶ï¸ ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤..."
docker-compose up -d

# 5. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
echo "ğŸ” ì„œë¹„ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤..."
sleep 10

if docker-compose ps | grep -q "Up"; then
    echo "âœ… ì„œë¹„ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!"
    echo ""
    echo "ğŸŒ ì„œë¹„ìŠ¤ URL:"
    echo "  - ì›¹ ì¸í„°í˜ì´ìŠ¤: http://localhost"
    echo "  - API ë¬¸ì„œ: http://localhost:8000/docs"
    echo "  - í—¬ìŠ¤ì²´í¬: http://localhost:8000/health"
    echo ""
    echo "ğŸ“Š ì‚¬ìš© ë°©ë²•:"
    echo "  1. ë¸Œë¼ìš°ì €ì—ì„œ http://localhost ì ‘ì†"
    echo "  2. ì›í•˜ëŠ” ë¦¬í¬íŠ¸ë¥¼ ìì—°ì–´ë¡œ ìš”ì²­"
    echo "  3. ìƒì„±ëœ ë¦¬í¬íŠ¸ URL í´ë¦­í•˜ì—¬ í™•ì¸"
else
    echo "âŒ ì„œë¹„ìŠ¤ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    echo "ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”: docker-compose logs"
fi
```

### scripts/download_model.py
```python
#!/usr/bin/env python3
"""
Qwen2.5-Coder ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
from pathlib import Path
from huggingface_hub import snapshot_download
from dotenv import load_dotenv

def main():
    # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    
    model_name = os.getenv('MODEL_NAME', 'Qwen/Qwen2.5-Coder-32B-Instruct')
    model_dir = Path('./models/qwen2.5-coder')
    
    print(f"ğŸ¤– {model_name} ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")
    print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {model_dir.absolute()}")
    
    try:
        # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        model_dir.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        snapshot_download(
            repo_id=model_name,
            local_dir=str(model_dir),
            resume_download=True
        )
        
        print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ëª¨ë¸ íŒŒì¼ í™•ì¸
        model_files = list(model_dir.rglob('*'))
        total_size = sum(f.stat().st_size for f in model_files if f.is_file())
        
        print(f"ğŸ“Š ë‹¤ìš´ë¡œë“œ ì™„ë£Œ:")
        print(f"  - íŒŒì¼ ìˆ˜: {len([f for f in model_files if f.is_file()])}")
        print(f"  - ì´ í¬ê¸°: {total_size / (1024**3):.2f} GB")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ìƒì—…ì  ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë©°, ììœ ë¡­ê²Œ ìˆ˜ì • ë° ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

ì´ READMEë¥¼ ì°¸ê³ í•˜ì—¬ ì™„ì „í•œ ì˜¤í”„ë¼ì¸ AI ë¦¬í¬íŠ¸ ìƒì„± ì„œë¹„ìŠ¤ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° êµ¬ì„± ìš”ì†ŒëŠ” ë…ë¦½ì ìœ¼ë¡œ ê°œë°œ ë° í…ŒìŠ¤íŠ¸ê°€ ê°€ëŠ¥í•˜ë©°, ì „ì²´ ì‹œìŠ¤í…œì€ í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.